{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "m58bD2TnHOWA"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import pandas as pd, numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, learning_curve\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (roc_auc_score, average_precision_score, accuracy_score,\n",
        "                             precision_score, recall_score, ConfusionMatrixDisplay)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip -q install kagglehub==0.2.5\n",
        "\n",
        "import os, pandas as pd, kagglehub\n",
        "\n",
        "# Download the dataset folder\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"ankushpanday1/alzheimers-prediction-dataset-global\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "jdosniT0U07r",
        "outputId": "52fbae2d-d3f5-411d-8626-8c169bdf2728"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'kagglehub' has no attribute 'dataset_download'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3352928588.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Download latest version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ankushpanday1/alzheimers-prediction-dataset-global\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Path to dataset files:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'kagglehub' has no attribute 'dataset_download'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_name = \"alzheimers_prediction_dataset.csv\"  # change if needed\n",
        "df = pd.read_csv(os.path.join(path, csv_name))\n",
        "\n",
        "print(\"Rows, Cols:\", df.shape)\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "zqhPRDImHjS0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "394b0814-da61-4462-cd1b-15cfa425cc3c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'path' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1762979100.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcsv_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"alzheimers_prediction_dataset.csv\"\u001b[0m  \u001b[0;31m# change if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rows, Cols:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing values, quick schema (A)\n",
        "# 1) Peek at dtypes and missingness\n",
        "print(\"Columns:\", list(df.columns))\n",
        "print(\"\\nDtypes:\\n\", df.dtypes)\n",
        "print(\"\\nMissing values (top 15):\\n\", df.isna().sum().sort_values(ascending=False).head(15))"
      ],
      "metadata": {
        "id": "3OEF8z6FVbfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a clean target column, target is Alzheimer's Diagnosis (B)\n",
        "# 2) Create binary target\n",
        "\n",
        "df = df.rename(columns={\"Alzheimer’s Diagnosis\": \"alz_dx\"})\n",
        "df[\"alz_dx\"] = df[\"alz_dx\"].map({\"Yes\": 1, \"No\": 0}).astype(\"int8\")\n",
        "\n",
        "# Quick check\n",
        "print(df[\"alz_dx\"].value_counts(dropna=False))"
      ],
      "metadata": {
        "id": "caekY9DaVcZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split coluns into numeric vs categorical (to plan preprocdssing) (C)\n",
        "num_cols = df.select_dtypes(include=[\"number\"]).columns.drop(\"alz_dx\", errors=\"ignore\").tolist()\n",
        "cat_cols = [c for c in df.columns if c not in num_cols + [\"alz_dx\"]]\n",
        "\n",
        "print(\"Numeric cols:\", len(num_cols), num_cols[:10], \"...\")\n",
        "print(\"Categorical cols:\", len(cat_cols), cat_cols[:10], \"...\")"
      ],
      "metadata": {
        "id": "Du9wRnOeVrfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/test split (stratified) (D)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(columns=['alz_dx'])\n",
        "y = df['alz_dx']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train shape:\", X_train.shape, \" Test shape:\", X_test.shape)\n",
        "print(\"Pos rate train/test:\", y_train.mean().round(3), y_test.mean().round(3))"
      ],
      "metadata": {
        "id": "gXXgkYJHWBoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing transformer (fit ONLY on train) (E)\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(with_mean=False), num_cols),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "\n",
        "# Fit on TRAIN only; transform both\n",
        "X_train_enc = preprocess.fit_transform(X_train)\n",
        "X_test_enc  = preprocess.transform(X_test)\n",
        "\n",
        "print(\"Encoded shapes:\", X_train_enc.shape, X_test_enc.shape)\n",
        "\n",
        "# (Optional) peek at generated feature names\n",
        "feat_names = preprocess.get_feature_names_out()\n",
        "print(\"Total features:\", len(feat_names))\n",
        "feat_names[:15]"
      ],
      "metadata": {
        "id": "YbLukrygWBrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a baseline Logisitic Regression (F)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
        "\n",
        "logit = LogisticRegression(\n",
        "    solver=\"saga\",        # handles sparse, many features\n",
        "    max_iter=2000,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "logit.fit(X_train_enc, y_train)\n",
        "\n",
        "y_pred = logit.predict(X_test_enc)\n",
        "y_proba = logit.predict_proba(X_test_enc)[:, 1]\n",
        "\n",
        "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred), 4))\n",
        "print(\"ROC-AUC :\", round(roc_auc_score(y_test, y_proba), 4))\n",
        "print()\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print()\n",
        "print(classification_report(y_test, y_pred, digits=4))\n"
      ],
      "metadata": {
        "id": "5lzEL0dpWBt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab top features (G)\n",
        "import numpy as np\n",
        "\n",
        "coefs = logit.coef_.ravel()\n",
        "top_idx = np.argsort(np.abs(coefs))[::-1][:15]\n",
        "for i in top_idx:\n",
        "    print(f\"{feat_names[i]:35s}  coef={coefs[i]: .4f}\")"
      ],
      "metadata": {
        "id": "02XxvQ9hWBwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Improve Logistic Regression (class_weight + C tuning) (H)\n",
        "# Goal is to boost recall/AUC with minimal complexity\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "grid = {\n",
        "    \"C\": [0.25, 0.5, 1.0, 2.0],\n",
        "    \"penalty\": [\"l2\"],             # stable with many one-hot features\n",
        "    \"class_weight\": [None, \"balanced\"],\n",
        "    \"solver\": [\"saga\"],\n",
        "    \"max_iter\": [2000]\n",
        "}\n",
        "\n",
        "logit = LogisticRegression(n_jobs=-1, random_state=42)\n",
        "gs = GridSearchCV(\n",
        "    logit, grid, scoring=\"roc_auc\", cv=cv, n_jobs=-1, refit=True, verbose=0\n",
        ")\n",
        "gs.fit(X_train_enc, y_train)\n",
        "\n",
        "print(\"Best params:\", gs.best_params_)\n",
        "print(\"CV AUC:\", round(gs.best_score_, 4))\n",
        "\n",
        "best_logit = gs.best_estimator_\n",
        "y_pred = best_logit.predict(X_test_enc)\n",
        "y_proba = best_logit.predict_proba(X_test_enc)[:, 1]\n",
        "\n",
        "print(\"Test Accuracy:\", round(accuracy_score(y_test, y_pred), 4))\n",
        "print(\"Test ROC-AUC :\", round(roc_auc_score(y_test, y_proba), 4))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, digits=4))"
      ],
      "metadata": {
        "id": "39uUcHtjWByR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tune decison threshold (single cell)\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_curve, confusion_matrix, classification_report, roc_auc_score, accuracy_score\n",
        "\n",
        "# Use whatever model/probas you already have; fall back to baseline `logit` if needed\n",
        "try:\n",
        "    y_scores = y_proba  # from your last model\n",
        "except NameError:\n",
        "    # fall back to baseline logistic if available\n",
        "    y_scores = logit.predict_proba(X_test_enc)[:, 1]\n",
        "\n",
        "prec, rec, thr = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "# 1) Maximize F1\n",
        "f1 = 2 * (prec * rec) / (prec + rec + 1e-12)\n",
        "best_idx = np.nanargmax(f1)\n",
        "best_thr_f1 = thr[best_idx] if best_idx < len(thr) else 0.5\n",
        "\n",
        "# 2) Or enforce a minimum precision and maximize recall under that precision (example: 0.70)\n",
        "min_precision = 0.70\n",
        "candidates = np.where(prec[:-1] >= min_precision)[0]\n",
        "best_thr_p70 = thr[candidates[np.argmax(rec[candidates])]] if len(candidates) else 0.5\n",
        "\n",
        "def eval_at(threshold, name):\n",
        "    y_hat = (y_scores >= threshold).astype(int)\n",
        "    print(f\"\\n{name} @ threshold={threshold:.3f}\")\n",
        "    print(\"Accuracy:\", round(accuracy_score(y_test, y_hat), 4))\n",
        "    print(\"AUC     :\", round(roc_auc_score(y_test, y_scores), 4))  # AUC doesn't change w/ threshold\n",
        "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_hat))\n",
        "    print(classification_report(y_test, y_hat, digits=4))\n",
        "\n",
        "eval_at(best_thr_f1,  \"Best F1\")\n",
        "eval_at(best_thr_p70, \"Max Recall with Precision≥0.70\")\n"
      ],
      "metadata": {
        "id": "uiFfVRACY4x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VjnB-XsFWB23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OzSdFsutWB5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v5VZbr2aWB7Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}